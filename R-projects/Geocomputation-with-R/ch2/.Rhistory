points(canterbury_height, col="red", pch=7)
points(nz_height, col="blue", pch=1)
#
plot(nz[1], col="NA", lwd=2, reset=F)
plot(canterbury, col="yellow", add=T)
plot(canterbury_height, col="red", pch=7, add=T)
plot(nz_height, col="blue", pch=1, add=T)
canterbury_height
nz_height[-canterbury_height]
nz_height[-canterbury_height,]
nz_height
canterbury_height
nz_height
nz_height[-canterbury_height$t50_fid,]
nz_height
canterbury_height$t50_fid
plot(nz_height[-canterbury_height$t50_fid,], col="blue", pch=1, add=T)
#
plot(nz[1], col="NA", lwd=2, reset=F)
plot(canterbury, col="yellow", add=T)
plot(canterbury_height, col="red", pch=7, add=T)
plot(nz_height[-canterbury_height$t50_fid,], col="blue", pch=1, add=T)
nz_height[-canterbury_height$t50_fid,]
nrow(nz_height[-canterbury_height$t50_fid,])
nrow(nz_height)
-canterbury_height$t50_fid
nz_height[-c(canterbury_height$t50_fid)
nrow
nz_height[-c(canterbury_height$t50_fid),]
nrow(nz_height[-c(canterbury_height$t50_fid),])
nz_height$t50_fid != canterbury_height$t50_fid
!nz_height$t50_fid==canterbury_height$t50_fid
row.names(canterbury_height)
row.names(nz_height)
nz_height[-as.numeric(row.names(canterbury_height)),]
#
plot(nz[1], col="NA", lwd=2, reset=F)
plot(canterbury, col="yellow", add=T)
plot(canterbury_height, col="red", pch=7, add=T)
plot(nz_height[-as.numeric(row.names(canterbury_height)),], col="blue", pch=1, add=T)
plot(nz_height[-as.numeric(row.names(canterbury_height)),], col="blue", pch=2, add=T)
#
plot(nz[1], col="NA", lwd=2, reset=F)
plot(canterbury, col="yellow", add=T)
plot(canterbury_height, col="red", pch=7, add=T)
plot(nz_height[-as.numeric(row.names(canterbury_height)),], col="blue", pch=1, add=T, lwd=2)
nrow(nz_height[-as.numeric(row.names(canterbury_height)),])
canterbury_height
canterbury
nz
nz_height[nz,]
st_join
st_join(nz_height, nz)
canterbury_height3
st_join(nz_height, nz["Name"])
# E2. Which region has the second highest number of nz_height points, and how many does it have?
st_join(nz_height, nz["Name"]) |>
group_by(Name) |>
summarise(count = n())
# E2. Which region has the second highest number of nz_height points, and how many does it have?
st_join(nz_height, nz["Name"]) |>
group_by(Name) |>
summarise(count = n(), desc=T)
# E2. Which region has the second highest number of nz_height points, and how many does it have?
st_join(nz_height, nz["Name"]) |>
group_by(Name) |>
summarise(count = n()) |>
arrange(count, desc=T)
# E2. Which region has the second highest number of nz_height points, and how many does it have?
st_join(nz_height, nz["Name"]) |>
group_by(Name) |>
summarise(count = n()) |>
arrange(count)
# E2. Which region has the second highest number of nz_height points, and how many does it have?
st_join(nz_height, nz["Name"]) |>
group_by(Name) |>
summarise(count = n()) |>
arrange(count, descending=T)
# E2. Which region has the second highest number of nz_height points, and how many does it have?
st_join(nz_height, nz["Name"]) |>
group_by(Name) |>
summarise(count = n()) |>
arrange(desc(count))
unique(nz["Name"])
unique(nz$Name)
nz_height
# E2. Which region has the second highest number of nz_height points, and how many does it have?
st_join(nz_height, nz["Name"]) |>
group_by(Name) |>
summarise(count = n()) |>
arrange(desc(count))
st_join(nz_height, nz["Name"]) |>
st_drop_geometry() |>
group_by(Name) |>
summarise(count = n()) |>
arrange(desc(count))
# E4. Test your knowledge of spatial predicates by finding out and
# plotting how US states relate to each other and other spatial objects.
colorado = us_states[us_states$NAME == "Colorado",]
plot(us_states, col="NA", lwd=2)
plot(us_states[1], col="NA", lwd=2)
plot(us_states[1], col="NA", lwd=2, reset=F)
plot(colorado, col="red", add=T)
# Create a new object representing all the states that geographically intersect with Colorado
# and plot the result (hint: the most concise way to do this is with the subsetting method [).
colorado[us_states,]
# Create another object representing all the objects that touch (have a shared boundary with)
# Colorado and plot the result (hint: remember you can use the argument op = st_intersects
# and other spatial relations during spatial subsetting operations in base R).
colorado[us_states, ,op=st_touches]
# Create a new object representing all the states that geographically intersect with Colorado
# and plot the result (hint: the most concise way to do this is with the subsetting method [).
us_states[colorado,]
# Create a new object representing all the states that geographically intersect with Colorado
# and plot the result (hint: the most concise way to do this is with the subsetting method [).
us_states[colorado,] |>
plot()
# Create a new object representing all the states that geographically intersect with Colorado
# and plot the result (hint: the most concise way to do this is with the subsetting method [).
us_states[colorado,] |>
plot(.[1])
# Create a new object representing all the states that geographically intersect with Colorado
# and plot the result (hint: the most concise way to do this is with the subsetting method [).
us_states[colorado,] |>
plot()[1]
# Create a new object representing all the states that geographically intersect with Colorado
# and plot the result (hint: the most concise way to do this is with the subsetting method [).
us_states[colorado,,op=st_touches] |>
plot()
# Create a new object representing all the states that geographically intersect with Colorado
# and plot the result (hint: the most concise way to do this is with the subsetting method [).
us_states[colorado,,op=st_intersects] |>
plot()
# Create another object representing all the objects that touch (have a shared boundary with)
# Colorado and plot the result (hint: remember you can use the argument op = st_intersects
# and other spatial relations during spatial subsetting operations in base R).
us_states[colorado, ,op=st_touches] |>
plot()
us_states$NAME
dc = us_states[us_states$NAME=="District of Columbia",]
cali = us_states[us_states$NAME=="California",]
plot(dc)
?st_union
?st_cast
st_union(dc, cali)
st_union(dc, cali) |>
plot()
plot(cali)
plot(dc)
st_union(dc, cali) |>
st_centroid()
st_union(dc, cali) #|>
dc
cali
st_union(dc, cali) |>
st_centroid() |>
st_cast()
st_union(dc, cali) |>
st_centroid() |> plot()
st_union(dc, cali)
dc
cali
st_union(st_centroid(dc), st_centroid(cali))
st_centroid(dc)
st_centroid(cali)
c(st_centroid(dc), st_centroid(cali))
st_union(st_centroid(dc), st_centroid(cali), by_feature = T)
c(st_centroid(dc), st_centroid(cali))
c(st_centroid(dc), st_centroid(cali)) |>
st_union()
st_sfc(st_centroid(dc), st_centroid(cali))
st_union(st_centroid(dc), st_centroid(cali)) |>
plot()
st_union(st_centroid(dc), st_centroid(cali)) |>
st_cast()
st_union(st_centroid(dc), st_centroid(cali)) |>
st_cast("LINESTRING")
st_union(st_centroid(dc), st_centroid(cali)) |>
st_cast("LINESTRING") |>
plot()
dc_cali_line = st_union(st_centroid(dc), st_centroid(cali)) |>
st_cast("LINESTRING") |>
plot()
dc_cali_line = st_union(st_centroid(dc), st_centroid(cali)) |>
st_cast("LINESTRING")
dc_cali_line
# Identify which states this long East-West line crosses
us_states[dc_cali_line,,op=st_within]
# Identify which states this long East-West line crosses
us_states[dc_cali_line,,op=st_intersects()]
# Identify which states this long East-West line crosses
us_states[dc_cali_line,,op=st_intersects]
# Identify which states this long East-West line crosses
us_states[dc_cali_line,,op=st_intersects] |>
plot()
# Identify which states this long East-West line crosses
us_states[dc_cali_line,,op=st_intersects] |>
plot(y="GEOID")
?plot.sf
# Identify which states this long East-West line crosses
us_states[dc_cali_line,,op=st_intersects] |>
plot(max.plot=1)
dem = rast(system.file("raster/dem.tif", package = "spDataLarge"))
# Get DEM & NDVI data
dem = rast(system.file("raster/dem.tif", package = "spDataLarge"))
(ndvi = rast(system.file("raster/ndvi.tif", package = "spDataLarge")))
# Reclassify DEM data in 3 classes
# Create a matrix of grouped intervals
rclm = matrix(c(NA, 300, 1, 300, 500, 2, 500, NA, 3), ncol = 3, byrow = TRUE)
rclm
# Use the classify command
reclm = classify(dem, rcl = rclm)
reclm
dem
reclm
recl
elev = rast(system.file("raster/elev.tif", package = "spData"))
grain = rast(system.file("raster/grain.tif", package = "spData"))
# To use coordinates for subsetting, one can ‘translate’ the coordinates into a cell ID
id = cellFromXY(elev, xy = matrix(c(0.1, 0.1), ncol = 2))
elev[id]
# the same as
terra::extract(elev, matrix(c(0.1, 0.1), ncol = 2))
# Raster objects can also be subset with another object as demonstrated in the code below:
clip = rast(xmin = 0.9, xmax = 1.8, ymin = -0.45, ymax = 0.45,
resolution = 0.3, vals = rep(1, 9))
elev[clip]
# we can also use extract
terra::extract(elev, terra::ext(clip))
# We can get spatial outputs from subset operations by setting drop arg in []
elev[1:2, drop = FALSE]    # spatial subsetting with cell IDs
# create raster mask
rmask = elev
values(rmask) = sample(c(NA, TRUE), 36, replace = TRUE)
# Next we want to keep those values in elev which are TRUE in rmask.
# In other words we want to mask elev with rmask
# spatial subsetting
elev[rmask, drop = FALSE]           # with [ operator
# we can also use mask
mask(elev, rmask)
# The above approach can also be used to replace some values
# (e.g. expected to be wrong) with NA values
elev[elev < 20] = NA
# 1. Local (or per cell) operations
elev + elev
elev^2
log(elev)
elev > 5
# Create a matrix of grouped intervals
rcl = matrix(c(0, 12, 1, 12, 24, 2, 24, 36, 3), ncol = 3, byrow = TRUE)
rcl
# Use the classify command
recl = classify(elev, rcl = rcl)
recl
elev
# Get DEM & NDVI data
dem = rast(system.file("raster/dem.tif", package = "spDataLarge"))
ndvi = rast(system.file("raster/ndvi.tif", package = "spDataLarge"))
dem
# Reclassify DEM data in 3 classes
# Create a matrix of grouped intervals
rclm = matrix(c(NA, 300, 1, 300, 500, 2, 500, NA, 3), ncol = 3, byrow = TRUE)
rclm
# Use the classify command
reclm = classify(dem, rcl = rclm)
reclm
# Reclassify DEM data in 3 classes
# Create a matrix of grouped intervals
rclm = matrix(c(0, 300, 1, 300, 500, 2, 500, NA, 3), ncol = 3, byrow = TRUE)
rclm
# Use the classify command
reclm = classify(dem, rcl = rclm)
reclm
# Reclassify DEM data in 3 classes
# Create a matrix of grouped intervals
rclm = matrix(c(0, 300, 1, 300, 500, 2, 500, 1094, 3), ncol = 3, byrow = TRUE)
rclm
# Use the classify command
reclm = classify(dem, rcl = rclm)
reclm
# Get DEM & NDVI data
dem = rast(system.file("raster/dem.tif", package = "spDataLarge"))
ndvi = rast(system.file("raster/ndvi.tif", package = "spDataLarge"))
# Reclassify DEM data in 3 classes
# Create a matrix of grouped intervals
rclm = matrix(c(0, 300, 1, 300, 500, 2, 500, 1094, 3), ncol = 3, byrow = TRUE)
rclm
# Use the classify command
dem_rec = classify(dem, rcl = rclm)
ndvi
# Compute the mean NDVI and elevation for each altitudinal class
zonal(ndvi, dem_rec)
zonal(dem, dem_rec)
?terra::focal()
?terra::focal()
?focal
img = rast(system.file("ex/logo.tif", package = "terra"))
plot(img)
rimg = rast(system.file("ex/logo.tif", package = "terra"))
plot(rimg)
?focal
focal(rimg, filter=matrix(c(0,1,0,1,-4,1,0,1,0), nrow=3))
rimgld = focal(rimg, filter=matrix(c(0,1,0,1,-4,1,0,1,0), nrow=3))
plot(rimgld)
plotRGB(rimgld)
plot(rimg)
plotRGB(rimgld)
rimgld = focal(rimg, w=matrix(c(0,1,0,1,-4,1,0,1,0), nrow=3))
plotRGB(rimgld)
# Apply the line detection Laplace n Sobel filters
rimgld = focal(rimg, w=matrix(c(0,1,0,1,-4,1,0,1,0), nrow=3))
plotRGB(rimgld)
# Calculate the NDWI of a Landsat image
ls = system.file("raster/landsat.tif", package = "spDataLarge")
ls
# Calculate the NDWI of a Landsat image
ls = rast(system.file("raster/landsat.tif", package = "spDataLarge"))
ls
(ls*0.0000275) - 0.2
# Rescale values in Landsat data
ls = (ls * 0.0000275) - 0.2
ls[ls < 0] = 0
# Calculate the NDWI of a Landsat image
ls = rast(system.file("raster/landsat.tif", package = "spDataLarge"))
# Rescale values in Landsat data
ls = (ls * 0.0000275) - 0.2
ls[ls < 0] = 0
ls
# Implement NDWI formula
ndwi_fun = function(green, nir){
(green - nir) / (green + nir)
}
ls[[c(2, 4)]]
# Implement NDWI formula
ndwi_fun = function(green, nir){
(green - nir) / (green + nir)
}
# We need to remember that our function expects two bands (not 4) from the original raster
ndwi_rast = lapp(ls[[c(2, 4)]], fun = ndwi_fun)
plot(ndwi_rast)
ndvi_rast = lapp(ls[[c(4, 3)]], fun = ndvi_fun)
plot(ndvi_rast)
# Compute corr btw NDVI and NDWI
layerCor(ndvi_rast, ndwi_rast)
ndvi_rast
ndwi_rast
# Compute corr btw NDVI and NDWI
layerCor(ndvi_rast, ndwi_rast, fun = "cor")
# Compute corr btw NDVI and NDWI
layerCor(c(ndvi_rast, ndwi_rast), fun = "cor")
names(ndvi_rast) = "ndvi"
names(ndwi_rast) = "ndwi"
# Compute corr btw NDVI and NDWI
layerCor(c(ndvi_rast, ndwi_rast), fun = "cor")
plot(elev)
nz
spain
Spain
esp
?spData
spData
data(wrld_simpl)
library(raster)
# Create a raster template for rasterizing the polys.
# (set the desired grid resolution with res)
r <- raster(xmn=-180, xmx=180, ymn=-90, ymx=90, res=1)
# Create a raster template for rasterizing the polys.
# (set the desired grid resolution with res)
r <- rast(xmn=-180, xmx=180, ymn=-90, ymx=90, res=1)
# Create a raster template for rasterizing the polys.
# (set the desired grid resolution with res)
r <- rast(xmin=-180, xmax=180, ymin=-90, ymax=90, res=1)
library(maptools)
install.packages('maptools', dependencies = T)
data("wrld_simpl")
data(wrld_simpl)
# E8. Compute the distance to the nearest coastline
library(maptools)
install.packages('maptools')
install.packages("maptools", repos = "https://packagemanager.posit.co/cran/2023-10-13")
# E8. Compute the distance to the nearest coastline
library(maptools)
library(raster)
data(wrld_simpl)
plot(wrld_simpl)
wrld_simpl$REGION
wrld_simpl$NAME
wrld_simpl[wrld_simpl$NAME=="Spain",]
plot(wrld_simpl[wrld_simpl$NAME=="Spain",])
ext(wrld_simpl[wrld_simpl$NAME=="Spain",])
ex <- drawExtent()
ex <- drawExtent()
ex
rm(ex)
ex
ex <- drawExtent()
# Prerequisites
library(sf)
library(terra)
library(dplyr)
library(spData)
library(spDataLarge)
# To simplify the river Seine and its tributaries.
seine_simp = st_simplify(seine, dTolerance = 2000)  # 2000 m dTolerance to control the level of generalization in map units
plot(seine_simp) # a copy of the original object but with fewer vertices
# This is apparent, with the result being visually simpler
# and consuming less memory than the original object, as verified below:
object.size(seine)
object.size(seine_simp)
# Simplification is also applicable for polygons. This is illustrated using us_states
# representing the contiguous US
us_states_simp1 = st_simplify(us_states, dTolerance = 100000)  # 100 km
plot(us_states_simp1)
# Simplify us_states keeping only 1% of the vertices of the input
# proportion of points to retain (0-1; default 0.05)
# The number of objects remains intact because we set keep_shapes=T
us_states_simp2 = rmapshaper::ms_simplify(us_states, keep = 0.01,
keep_shapes = TRUE)
plot(us_states_simp2)
# using Gaussian kernel regression to smooth the borders of US states by using method=ksmooth
us_states_simp3 = smoothr::smooth(us_states, method = "ksmooth", smoothness = 6)
plot(us_states_simp3)
# CENTROIDS
# Generate centroids for regions in New Zealand and tributaries to the River Seine
nz_centroid = st_centroid(nz)
seine_centroid = st_centroid(seine)
b = st_sfc(st_point(c(0, 1)), st_point(c(1, 1))) # create 2 points
b = st_buffer(b, dist = 1) # convert points to circles
plot(b, border = "grey")
text(x = c(-0.5, 1.5), y = 1, labels = c("x", "y"), cex = 3) # add text
# Imagine you want to select not one circle/the other but the space coverd by both circles
x = b[1]
y = b[2]
x_and_y = st_intersection(x, y)
plot(b, border = "grey")
plot(x_and_y, col = "lightgrey", border = "grey", add = TRUE) # intersecting area
# SUBSETTING & CLIPPING
# Clipping objects can change their geometry but it can also subset objects,
# returning only features that intersect (or partly intersect) with a clipping/subsetting object.
# To illustrate this point, we will subset points that cover the bounding box of the circles x and y
bb = st_bbox(st_union(x, y))
box = st_as_sfc(bb)
set.seed(2024)
p = st_sample(x = box, size = 10)   # generate a simple random distribution of points within the bb of the circles
p_xy1 = p[x_and_y]
plot(box, border = "grey", lty = 2)
plot(x, add = TRUE, border = "grey")
plot(y, add = TRUE, border = "grey")
plot(p, add = TRUE, cex = 3.5)
plot(p_xy1, cex = 5, col = "red", add = TRUE)
text(x = c(-0.5, 1.5), y = 1, labels = c("x", "y"), cex = 3)
# way #1
p_xy1 = p[x_and_y]
# way #2
p_xy2 = st_intersection(p, x_and_y)
# way #3
sel_p_xy = st_intersects(p, x, sparse = FALSE)[, 1] &
st_intersects(p, y, sparse = FALSE)[, 1]
p_xy3 = p[sel_p_xy]
# GEOMETRY UNIONS
# As we've seen, spatial aggregation can silently dissolve the geometries of touching polygons
# in the same group. Below we aggregate the 48 US states n the district of columbia into 4 regions
# using base n dplyr functions
regions = aggregate(x = us_states[, "total_pop_15"],
by = list(us_states$REGION),
FUN = sum, na.rm = TRUE)
regions2 = us_states |>
group_by(REGION) |>
summarize(pop = sum(total_pop_15, na.rm = TRUE))
plot(regions2)
# Behind the scenes, both aggregate & summarize combine the geometries and dissolve the boundaries
# btw them using st_union. This is demonstrated below which creates a united western US
us_west = us_states[us_states$REGION == "West", ]
us_west_union = st_union(us_west)
plot(us_west_union)
# the function can take any two geometries and unite them:
texas = us_states[us_states$NAME == "Texas", ]
texas_union = st_union(us_west_union, texas)
plot(texas_union)
# TYPE TRANSFORMATIONS
# Geometry casting is a powerful operation that enables transformation of the geometry type
# st_cast behaves differently on sfg objects, sfc and simple feature objects
# Let's create a multipoint to illustrate how geometry casting works on sfg objects:
multipoint = st_multipoint(matrix(c(1, 3, 5, 1, 3, 1), ncol = 2))
plot(multipoint)
# In this case, st_cast can be used to transform the multipoint into a line/polygon
linestring = st_cast(multipoint, "LINESTRING")
polyg = st_cast(multipoint, "POLYGON")
plot(linestring); plot(polyg)
# The transformation can also be reversed using st_cast
multipoint_2 = st_cast(linestring, "MULTIPOINT")
multipoint_3 = st_cast(polyg, "MULTIPOINT")
all.equal(multipoint, multipoint_2)
all.equal(multipoint, multipoint_3)
# Let's try to apply geometry type transformations on a new object
# multilinestring_sf as an example
multilinestring_list = list(matrix(c(1, 4, 5, 3), ncol = 2),
matrix(c(4, 4, 4, 1), ncol = 2),
matrix(c(2, 4, 2, 2), ncol = 2))
multilinestring = st_multilinestring(multilinestring_list)
multilinestring_sf = st_sf(geom = st_sfc(multilinestring))
multilinestring_sf
multilinestring
multilinestring_sf = st_sf(geom = st_sfc(multilinestring))
multilinestring_sf
# Separate this multilinestring into 3 linestrings
linestring_sf2 = st_cast(multilinestring_sf, "LINESTRING")
linestring_sf2
# The newly created object allows for attribute creation and length measurement
linestring_sf2$name = c("Riddle Rd", "Marshall Ave", "Foulke St")
linestring_sf2$length = st_length(linestring_sf2)
linestring_sf2
