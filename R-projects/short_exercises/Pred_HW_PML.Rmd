---
title: "Predicting activity performance with machine learning methods"
author: "Emmanuel Adeleke"
output: 
  pdf_document: default
  html_document: 
    keep_md: yes
---

## Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

## Load all required libraries

```{r}
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)

```



## Data collection and splitting

First, we load the dataset from online sources and split them into 75% training and 25% testing sets

```{r data, echo=TRUE}

train_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"

test_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"


train <- read.csv(url(train_url))
test <- read.csv(url(test_url))


inTrain <- createDataPartition(train$classe, p = 0.75, list=F)
training <- train[inTrain, ]
testing <- train[-inTrain, ]

```

## Data Cleaning

```{r str, echo=T}
# Looking at the structure of the training and testing datasets. 
# str(training)
# str(testing)

```

Now we remove zero variance variables and other irrelevant variables from the data. In addition, we drop variables that contain NA values

```{r split, echo=T}

NZV <- nearZeroVar(training)
training <- training[,-NZV]
testing <- testing[, -NZV]

NAvar <- apply(training, 2, function(x) mean(is.na(x))) < 0.60

training <- training[,NAvar]
testing <- testing[,NAvar]

# remove first 5 irrelevant variables
training <- training[,-c(1:5)]
testing <- testing[,-c(1:5)]

# convert the 'classe' column to factor
training$classe <- as.factor(training$classe)
testing$classe <- as.factor(testing$classe)
```

## Predictive modelling

Here, we will train 3 machine learning modelling algroithms and select the best among these having the best prediction accuracy on the testing set. The algorithms used are Decision Tree, Random Forest and Generalized Boosted Model. 

## 1. Decision Tree 

```{r decisionTree, echo=T, message = F, warning=F}
set.seed(1234)
modelfitDT <- rpart(classe ~ .,data=training, method = "class")
```

## Dendrogram

```{r dendrogram, echo=FALSE, fig.width=18, fig.height=10}
fancyRpartPlot(modelfitDT)
```

## Prediction and confusion matrix
```{r}
predictDT <- predict(modelfitDT, testing, type = "class")
confuMatDT <- confusionMatrix(predictDT, testing$classe)
confuMatDT
```

## 2. Random Forest

```{r rf, echo=T}
set.seed(1234)
modelfitRF <- train(classe~., data=training, method="rf", trControl=trainControl(method = "cv", number = 5, verboseIter = F))

predictRF <- predict(modelfitRF, testing)
confuMatRF <- confusionMatrix(predictRF, testing$classe)
confuMatRF


```

## Generalized Boosted Model

```{r gbm, message=F, warning=F}

set.seed(1234)
trControl <- trainControl(method = "repeatedcv", number = 5, repeats = 1, verboseIter = F)
modelfitGBM <- train(classe~., data=training, trControl=trControl, method="gbm", verbose=F)

predictGBM <- predict(modelfitGBM, testing)
confuMatGBM <- confusionMatrix(predictGBM, testing$classe)
confuMatGBM

```

## Results 

We choose the Random Forest model because it has the highest accuracy 0.99 on the testing set. We therefore use the RF model for out of sample prediction on the new testing dataset. 

```{r prediction, message=F}
prediction <- predict(modelfitRF, test)
prediction

```

